---
title: "R Notebook"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

# <font color='#31708f'>Zendesk Tickets Word Cloud</font>

* [Preprocessing](#second-bullet)

* [WordCloud](#third-bullet)

* [CountVectorizer](#fourth-bullet)

* [LDA Model](#fifth-bullet)

Install package management system 'renv' to ensure packages are installed in the project-specific environment:
```{r}
install.packages("renv")
```

Set your working directory to the project folder.
```{r}
setwd("/home/smsta/Desktop/zendesk_tag_cloud/newman")
```

Activate 'renv' in the project:
```{r}
# Load the renv library
library(renv)

# Initialize renv in the project
renv::init()
```

# <font color='#31708f'>Preprocessing</font>

Display the path of current directory:
```{r}
getwd()
```

```{r}
#Make sure code returns a list of files. List all json files in newman folder, sorted in ascending order
file_list <- list.files(path = "/home/smsta/Desktop/zendesk_tag_cloud/newman", pattern = "*.json")
print(file_list)
```

Install and load the jsonlite package:
```{r}
renv::install("jsonlite")
```

Set your working directory to the project folder.
```{r}
setwd("/home/smsta/Desktop/zendesk_tag_cloud/newman")
```

Read json objects
```{r}
library(jsonlite)

# Specify the file path
file_path <- "/home/smsta/Desktop/zendesk_tag_cloud/newman/newman-run-report-2020-06-25-06-42-13-124-0-ticketid-upto-3000.json"

# Use fromJSON to read the JSON data from the file
x <- fromJSON(file_path)

# Print the first few elements of the resulting object
head(x, 6)
```

Parse json file:
```{r}
library(jsonlite)

file_path <- 'newman-run-report-2020-06-25-06-42-13-124-0-ticketid-upto-3000.json'
json_data <- fromJSON(file_path, flatten = TRUE)

generate_event_tuples <- function(json_data, prefix = NULL) {
  events <- list()

  if (is.list(json_data)) {
    for (key in names(json_data)) {
      current_path <- if (is.null(prefix)) key else paste0(prefix, ".", key)
      value <- json_data[[key]]

      if (is.list(value)) {
        # Recursively call the function for nested objects
        events <- c(events, generate_event_tuples(value, prefix = current_path))
      } else {
        # Add the current key, path, and value to the events list
        events <- c(events, list(c(prefix = current_path, event = key, value = value)))
      }
    }
  } else {
    # Handling named vectors or atomic vectors
    current_path <- if (is.null(prefix)) "root" else prefix
    events <- list(c(prefix = current_path, event = "", value = json_data))
  }

  return(events)
}

result_events <- generate_event_tuples(json_data)

for (event in result_events) {
  cat(sprintf("prefix = %s, event = %s, value = %s\n", event[['prefix']], event[['event']], event[['value']]))
}
```

Parse json files in a folder:
```{r}
library(jsonlite)

for (json_file in file_list) {
  json_data <- fromJSON(json_file)
  
  # Assuming json_data is a list of events
  for (event in json_data) {
    cat(sprintf("prefix = %s, event = %s, value = %s\n", event$prefix, event$event, event$value))
  }
}
```


```{r}
setwd("/home/smsta/Desktop")
```

```{r}
# Remove escaped newline '\\n' and non-breaking space 'nbsp' characters
  m <- lapply(json_data, function(x) str_replace_all(x, '\\\\n|nbsp', ' '))
  print(m)
```

```{r}
# Load the jsonlite package
library(jsonlite)

# Define a function for streaming JSON parsing
parse_json <- function(json_filename) {
  # Open a connection to the JSON file
  con <- file(json_filename, "r", encoding = "UTF-8")

  # Create a JSON streaming parser
  parser <- stream_in(con)

  # Iterate through the parsed JSON data
  while (length(parser) > 0) {
    # Process each JSON record
    print(parser)

    # Continue parsing the next JSON record
    parser <- stream_in(con, parser)
  }

  # Close the file connection
  close(con)
}

# Specify the JSON file to parse
json_filename <- "newman-run-report-2020-06-25-06-42-13-124-0-ticketid-upto-3000.json"

# Call the parse_json function
parse_json(json_filename)

```

Show all keys in json file:
```{r}
# Load the jsonlite package
library(jsonlite)

# Function to recursively show all keys
show_all_keys <- function(json_data, parent_key = NULL) {
  if (is.list(json_data)) {
    for (key in names(json_data)) {
      nested_key <- ifelse(is.null(parent_key), key, paste(parent_key, key, sep = "."))
      print(nested_key)
      show_all_keys(json_data[[key]], nested_key)
    }
  }
}

# Specify the path to the JSON file
json_file_path <- "/home/smsta/Desktop/zendesk_tag_cloud/newman/newman-run-report-2020-06-25-06-42-13-124-0-ticketid-upto-3000.json"

# Read and parse the JSON file
json_data <- fromJSON(json_file_path)

# Show all keys
print("All Keys:")
show_all_keys(json_data)

```

Access data inside key "assertions":
```{r}
assertions_data <- json_data$run$executions$assertions
assertions_data
```

Extract the substring between two markers:
```{r}
library(stringr)
l <- str_match(assertions_data, "(?<=plain_body)(.+?)(?=public)")
l[1:6]
```

Perform text preprocessing:
```{r}
# Remove escaped newline '\\n' and non-breaking space 'nbsp' characters
m <- gsub("\\\\n|nbsp|\\\\", " ", l, perl = TRUE)
# Remove any URL within a string
p <- gsub("http\\S+|www\\S+", '', m, perl = TRUE)
# Remove all of the punctuation
library(stringi)
q <- gsub("[[:punct:]]", "", p , perl = TRUE)
q[1:6]
```

```{r}
setwd("/home/smsta/Desktop/zendesk_tag_cloud/zendesk_txt")
```


```{r}
install.packages("gtools")
```

```{r}
library(gtools)
```

Control order of results:
```{r}
# Set the directory path
directory_path <- "/home/smsta/Desktop/zendesk_tag_cloud/zendesk_txt"

# List all files in the directory
all_txt_files <- list.files(path = directory_path, pattern = "\\.txt$", full.names = TRUE)

# Sort the file names alphabetically
all_txt_files <- sort(all_txt_files)

# Sort file names based on numbers
sorted_file_names <- all_txt_files[order(file_numbers)]

# Print the first 6 file names
print(sorted_file_names[1:6])

# Count the number of files
length(all_txt_files)

```



Install the necessary packages: 
```{r}
install.packages("tm")
install.packages("wordcloud")
install.packages("RColorBrewer")

```



```{r}
install.packages("textTinyR")
```

```{r}
library(textTinyR)

```{r}
install.packages(c("tm", "wordcloud"))
```

Generate a word cloud from a directory of text files
```{r}
library(tm)
library(wordcloud)

# Specify the path to the directory containing your text files
directory_path <- "/home/smsta/Desktop/zendesk_tag_cloud/zendesk_txt"

# Create a corpus for all documents
corpus <- Corpus(DirSource(directory_path, encoding = "UTF-8"))

# Sample a subset of documents
sample_corpus <- corpus[sample(length(corpus), 1000)]  # Adjust the number as needed

# Create a term-document matrix for the subset corpus
tdm <- TermDocumentMatrix(sample_corpus, control = list(wordLengths = c(1, Inf)))

# Get the word frequencies directly from the TermDocumentMatrix
word_freq <- rowSums(as.matrix(tdm))

# Order the words by frequency and select the top 1000 words
top_words <- head(sort(word_freq, decreasing = TRUE), 1000)
top_words

```

Set figure size:
```{r}
# Adjust plot margins
par(mar = c(0.2, 0.2, 0.2, 0.2))  # Set smaller margins (bottom, left, top, right)

# Generate a word cloud
wordcloud(words = names(top_words), freq = top_words, min.freq = 1, colors = brewer.pal(8, "Dark2"))
```

```{r}
set.seed(123) # for reproducibility
wordcloud(words = rownames(word_freq), 
          freq = word_freq$Freq, 
          min.freq = 1, 
          max.words = 100, 
          random.order = FALSE, 
          colors = brewer.pal(8, "Dark2"))
```

